#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SODR√â SANTORO - SCRAPER COM CATEGORIZA√á√ÉO REFINADA
‚úÖ Mapeamento completo para 10 categorias principais
‚úÖ Pagina√ß√£o robusta - n√£o para prematuramente
‚úÖ Espera adaptativa por se√ß√£o
‚úÖ Deduplica√ß√£o na coleta
‚úÖ Mapeamento completo dos campos
"""

import asyncio
import sys
import json
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict
from playwright.async_api import async_playwright

sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from supabase_client_fixed import SupabaseClient
except:
    try:
        from supabase_client import SupabaseClient
    except:
        SupabaseClient = None


class SodreScraperCategorizado:
    """Scraper Sodr√© - Com Categoriza√ß√£o Refinada"""
    
    def __init__(self, debug=False):
        self.source = 'sodre'
        self.base_url = 'https://www.sodresantoro.com.br'
        self.debug = debug
        
        # ‚úÖ Configura√ß√£o otimizada por se√ß√£o
        self.section_config = {
            'veiculos': {'wait_time': 7, 'max_retries': 3, 'max_pages': 200},
            'imoveis': {'wait_time': 7, 'max_retries': 3, 'max_pages': 50},
            'materiais': {'wait_time': 7, 'max_retries': 3, 'max_pages': 200},
            'sucatas': {'wait_time': 12, 'max_retries': 4, 'max_pages': 200},
        }
        
        self.urls = [
            f"{self.base_url}/veiculos/lotes?sort=auction_date_init_asc",
            f"{self.base_url}/imoveis/lotes?sort=auction_date_init_asc",
            f"{self.base_url}/materiais/lotes?sort=auction_date_init_asc",
            f"{self.base_url}/sucatas/lotes?sort=auction_date_init_asc",
        ]
        
        self.stats = {
            'total_scraped': 0,
            'duplicates': 0,
            'with_bids': 0,
            'errors': 0,
        }
        
        self.section_counters = {}
        
        # üî• MAPEAMENTO COMPLETO: subcategorias ‚Üí 10 categorias principais
        self.category_mapping = {
            # ========================================
            # 1Ô∏è‚É£ IM√ìVEIS
            # ========================================
            'apartamento': 'Im√≥veis',
            'casa': 'Im√≥veis',
            'casa / constru√ß√£o': 'Im√≥veis',
            'complexo industrial': 'Im√≥veis',
            'complexo residencial e de lazer': 'Im√≥veis',
            'direitos sobre apartamento': 'Im√≥veis',
            'direitos sobre im√≥vel residencial': 'Im√≥veis',
            'direitos sobre terreno': 'Im√≥veis',
            'galp√£o industrial': 'Im√≥veis',
            'galp√µes comerciais e resid√™ncia': 'Im√≥veis',
            'gleba de terra': 'Im√≥veis',
            'im√≥vel comercial e residencial': 'Im√≥veis',
            'im√≥vel residencial': 'Im√≥veis',
            'im√≥vel residencial com 3 edifica√ß√µes': 'Im√≥veis',
            'im√≥vel residencial tipo sobrado': 'Im√≥veis',
            'lote de terreno': 'Im√≥veis',
            'parte ideal de 1/6 sobre im√≥vel residencial': 'Im√≥veis',
            'parte ideal de 50% sobre lote de terreno': 'Im√≥veis',
            'parte ideal de 50% sobre nua-propriedade': 'Im√≥veis',
            'terreno': 'Im√≥veis',
            'terreno urbano': 'Im√≥veis',
            '√°rea de terras': 'Im√≥veis',
            
            # ========================================
            # 2Ô∏è‚É£ VE√çCULOS
            # ========================================
            'caminh√µes': 'Ve√≠culos',
            'carros': 'Ve√≠culos',
            'embarca√ß√µes': 'Ve√≠culos',
            'motos': 'Ve√≠culos',
            'onibus': 'Ve√≠culos',
            'peruas': 'Ve√≠culos',
            'utilit. pesados': 'Ve√≠culos',
            'utilitarios leves': 'Ve√≠culos',
            'van leve': 'Ve√≠culos',
            've√≠culos': 'Ve√≠culos',
            'bicicleta': 'Ve√≠culos',
            
            # ========================================
            # 3Ô∏è‚É£ M√ÅQUINAS & EQUIPAMENTOS
            # ========================================
            'compressores de ar': 'M√°quinas & Equipamentos',
            'empilhadeiras': 'M√°quinas & Equipamentos',
            'equip. e mat. industriais': 'M√°quinas & Equipamentos',
            'geradores': 'M√°quinas & Equipamentos',
            'implementos agr√≠colas': 'M√°quinas & Equipamentos',
            'implementos rod.': 'M√°quinas & Equipamentos',
            'terraplenagem': 'M√°quinas & Equipamentos',
            'tratores': 'M√°quinas & Equipamentos',
            
            # ========================================
            # 4Ô∏è‚É£ TECNOLOGIA
            # ========================================
            'eletricos': 'Tecnologia',
            'informatica': 'Tecnologia',
            '√°udio, v√≠deo e ilumina√ß√£o': 'Tecnologia',
            'eletrodomesticos': 'Tecnologia',  # Alguns eletrodom√©sticos s√£o tech (TVs, etc)
            
            # ========================================
            # 5Ô∏è‚É£ CASA & CONSUMO
            # ========================================
            'moveis para escrit√≥rio': 'Casa & Consumo',
            'm√≥veis p/ casa': 'Casa & Consumo',
            'lazer/esportes': 'Casa & Consumo',
            'uso pessoal': 'Casa & Consumo',
            'materiais escolares': 'Casa & Consumo',
            
            # ========================================
            # 6Ô∏è‚É£ INDUSTRIAL & EMPRESARIAL
            # ========================================
            'academia': 'Industrial & Empresarial',
            'esquadrias e estruturas met√°licas': 'Industrial & Empresarial',
            'ferramentas': 'Industrial & Empresarial',
            'hospitalar': 'Industrial & Empresarial',
            
            # ========================================
            # 7Ô∏è‚É£ MATERIAIS & SUCATAS
            # ========================================
            'diversos': 'Materiais & Sucatas',
            
            # ========================================
            # 9Ô∏è‚É£ ARTE & COLECION√ÅVEIS
            # ========================================
            'instrumentos musicais': 'Arte & Colecion√°veis',
            
            # ========================================
            # üîü OUTROS
            # ========================================
            'unknown': 'Outros',
        }
    
    def _categorize_item(self, subcategory: str) -> str:
        """
        Mapeia subcategoria original do Sodr√© para uma das 10 categorias principais
        
        Args:
            subcategory: Subcategoria original (ex: 'carros', 'apartamento', 'informatica')
        
        Returns:
            Uma das 10 categorias principais
        """
        if not subcategory:
            return 'Outros'
        
        # Normaliza
        subcategory_clean = subcategory.lower().strip()
        
        # Busca no mapeamento
        category = self.category_mapping.get(subcategory_clean)
        
        if category:
            return category
        
        # Fallback: tenta detectar pela subcategoria
        if 'imovel' in subcategory_clean or 'im√≥vel' in subcategory_clean or \
           'apartamento' in subcategory_clean or 'casa' in subcategory_clean or \
           'terreno' in subcategory_clean or 'galp√£o' in subcategory_clean:
            return 'Im√≥veis'
        
        if 'carro' in subcategory_clean or 'moto' in subcategory_clean or \
           'caminh√£o' in subcategory_clean or 've√≠culo' in subcategory_clean or \
           'veiculo' in subcategory_clean or '√¥nibus' in subcategory_clean:
            return 'Ve√≠culos'
        
        if 'trator' in subcategory_clean or 'empilhadeira' in subcategory_clean or \
           'gerador' in subcategory_clean or 'compressor' in subcategory_clean or \
           'implemento' in subcategory_clean:
            return 'M√°quinas & Equipamentos'
        
        if 'inform√°tica' in subcategory_clean or 'informatica' in subcategory_clean or \
           'eletron' in subcategory_clean or 'eletr' in subcategory_clean or \
           '√°udio' in subcategory_clean or 'audio' in subcategory_clean:
            return 'Tecnologia'
        
        if 'm√≥vel' in subcategory_clean or 'movel' in subcategory_clean or \
           'lazer' in subcategory_clean or 'esporte' in subcategory_clean:
            return 'Casa & Consumo'
        
        if 'ferramenta' in subcategory_clean or 'industrial' in subcategory_clean or \
           'academia' in subcategory_clean or 'hospitalar' in subcategory_clean:
            return 'Industrial & Empresarial'
        
        if 'sucata' in subcategory_clean or 'material' in subcategory_clean or \
           'diversos' in subcategory_clean:
            return 'Materiais & Sucatas'
        
        if 'instrumento' in subcategory_clean or 'musical' in subcategory_clean or \
           'arte' in subcategory_clean or 'colecion√°vel' in subcategory_clean:
            return 'Arte & Colecion√°veis'
        
        # Default
        return 'Outros'
    
    async def scrape(self) -> List[Dict]:
        """Scrape completo com intercepta√ß√£o passiva"""
        print("\n" + "="*60)
        print("üü£ SODR√â SANTORO - VERS√ÉO CATEGORIZADA")
        print("="*60)
        
        all_lots = []
        seen_lot_ids = set()  # ‚úÖ Deduplica√ß√£o na coleta
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            context = await browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                locale='pt-BR'
            )
            
            page = await context.new_page()
            
            current_section = {'name': None, 'api_calls': 0, 'last_capture': 0}
            
            async def intercept_response(response):
                try:
                    if '/api/search-lots' in response.url and response.status == 200:
                        current_section['api_calls'] += 1
                        
                        data = await response.json()
                        per_page = data.get('perPage', 0)
                        
                        if per_page > 0:
                            results = data.get('results', [])
                            hits = data.get('hits', {}).get('hits', [])
                            
                            lots_captured = 0
                            new_lots = 0
                            
                            # Extrai lotes da resposta
                            lots_to_add = []
                            if results:
                                lots_to_add = results
                            elif hits:
                                lots_to_add = [hit.get('_source', hit) for hit in hits]
                            
                            # ‚úÖ Deduplica durante a coleta
                            for lot in lots_to_add:
                                lot_id = lot.get('id') or lot.get('lot_id')
                                if lot_id and lot_id not in seen_lot_ids:
                                    seen_lot_ids.add(lot_id)
                                    all_lots.append(lot)
                                    new_lots += 1
                            
                            if new_lots > 0:
                                current_section['last_capture'] = time.time()
                                section = current_section['name']
                                if section not in self.section_counters:
                                    self.section_counters[section] = 0
                                self.section_counters[section] += new_lots
                                
                                print(f"     üì• API call #{current_section['api_calls']}: +{new_lots} lotes √∫nicos | Total: {self.section_counters[section]}")
                            else:
                                if self.debug:
                                    total = len(lots_to_add)
                                    print(f"     ‚ö™ API call #{current_section['api_calls']}: 0 novos ({total} duplicatas)")
                except:
                    pass
            
            page.on('response', intercept_response)
            
            for url in self.urls:
                section_name = url.split('/')[3]
                current_section['name'] = section_name
                current_section['api_calls'] = 0
                current_section['last_capture'] = 0
                
                config = self.section_config.get(section_name, {'wait_time': 7, 'max_retries': 3, 'max_pages': 200})
                
                lots_before = len(all_lots)
                
                print(f"\nüì¶ {section_name.upper()}")
                print(f"  ‚è±Ô∏è Tempo de espera: {config['wait_time']}s | M√°x p√°ginas: {config['max_pages']}")
                
                try:
                    await page.goto(url, wait_until="networkidle", timeout=60000)
                    
                    print(f"  ‚è≥ Aguardando carregamento inicial...")
                    
                    # ‚úÖ Espera inicial adaptativa
                    for attempt in range(config['max_retries']):
                        await asyncio.sleep(config['wait_time'])
                        
                        lots_after = len(all_lots)
                        new_lots = lots_after - lots_before
                        
                        if new_lots > 0:
                            print(f"  ‚úÖ Tentativa {attempt + 1}: {new_lots} lotes capturados")
                            break
                        else:
                            if attempt < config['max_retries'] - 1:
                                print(f"  üîÑ Tentativa {attempt + 1}: Aguardando mais dados...")
                            else:
                                print(f"  ‚ö†Ô∏è Tentativa {attempt + 1}: Nenhum dado capturado")
                    
                    # ‚úÖ PAGINA√á√ÉO ROBUSTA
                    if len(all_lots) > lots_before:
                        # Contador de tentativas sem sucesso de CLICK (n√£o de dados)
                        failed_clicks = 0
                        max_failed_clicks = 5
                        
                        for page_num in range(2, config['max_pages'] + 1):
                            try:
                                # Scroll
                                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                                await asyncio.sleep(1)
                                
                                # Tenta clicar no bot√£o "pr√≥xima"
                                button_clicked = False
                                
                                # Seletores poss√≠veis
                                next_selectors = [
                                    'button:has-text("Pr√≥xima")',
                                    'button:has-text("pr√≥xima")',
                                    'a:has-text("Pr√≥xima")',
                                    'a:has-text("pr√≥xima")',
                                    '[aria-label*="pr√≥xima" i]',
                                    '[aria-label*="next" i]',
                                    'button.pagination-next',
                                    'a.pagination-next',
                                ]
                                
                                for selector in next_selectors:
                                    try:
                                        btn = page.locator(selector).first
                                        if await btn.is_visible(timeout=2000):
                                            await btn.click(timeout=5000)
                                            button_clicked = True
                                            print(f"  ‚û°Ô∏è P√°gina {page_num}...")
                                            break
                                    except:
                                        continue
                                
                                if not button_clicked:
                                    failed_clicks += 1
                                    if failed_clicks >= max_failed_clicks:
                                        print(f"  ‚úÖ {page_num - 1} p√°ginas - fim detectado")
                                        break
                                    continue
                                else:
                                    failed_clicks = 0  # Reset contador
                                
                                # Espera dados novos
                                lots_before_page = len(all_lots)
                                time_waited = 0
                                max_wait = 15
                                
                                while time_waited < max_wait:
                                    await asyncio.sleep(2)
                                    time_waited += 2
                                    
                                    lots_now = len(all_lots)
                                    if lots_now > lots_before_page:
                                        break
                                
                                # Se n√£o capturou nada novo ap√≥s espera m√°xima
                                if len(all_lots) == lots_before_page:
                                    print(f"  ‚ö†Ô∏è P√°gina {page_num}: Sem novos dados ap√≥s {max_wait}s")
                                    failed_clicks += 1
                                    if failed_clicks >= max_failed_clicks:
                                        print(f"  ‚úÖ {page_num - 1} p√°ginas - fim por timeout")
                                        break
                            
                            except Exception as e:
                                if self.debug:
                                    print(f"  ‚ö†Ô∏è Erro na p√°gina {page_num}: {e}")
                                failed_clicks += 1
                                if failed_clicks >= max_failed_clicks:
                                    break
                                await asyncio.sleep(2)
                        
                        section_total = len(all_lots) - lots_before
                        print(f"  ‚úÖ TOTAL DA SE√á√ÉO: {section_total} lotes √∫nicos")
                
                except Exception as e:
                    print(f"  ‚ùå Erro na se√ß√£o {section_name}: {e}")
                    self.stats['errors'] += 1
            
            await browser.close()
        
        print(f"\n‚úÖ {len(all_lots)} lotes √∫nicos capturados no total")
        
        # Normaliza dados
        normalized_items = []
        category_stats = {}
        
        for lot in all_lots:
            normalized = self._normalize_lot(lot)
            if normalized:
                normalized_items.append(normalized)
                
                # Atualiza estat√≠sticas por categoria
                cat = normalized.get('categoria', 'Outros')
                if cat not in category_stats:
                    category_stats[cat] = 0
                category_stats[cat] += 1
        
        # Mostra estat√≠sticas por categoria
        print(f"\nüìä Por Categoria Principal:")
        for cat in sorted(category_stats.keys()):
            count = category_stats[cat]
            print(f"  ‚Ä¢ {cat}: {count} itens")
        
        self.stats['total_scraped'] = len(normalized_items)
        
        return normalized_items
    
    def _normalize_lot(self, lot: Dict) -> Dict:
        """
        Normaliza lote para schema do Supabase + adiciona categoria principal
        """
        try:
            # Extrai subcategoria original
            subcategory = self._safe_str(lot.get('lot_subcategory') or lot.get('subcategory'))
            
            # üî• CATEGORIZA com base na subcategoria
            categoria_principal = self._categorize_item(subcategory)
            
            # Conta itens com lances
            if lot.get('lot_has_bid') or lot.get('lot_auction_date_init'):
                self.stats['with_bids'] += 1
            
            item = {
                'source': self.source,
                'external_id': self._safe_str(lot.get('id') or lot.get('lot_id')),
                
                # üî• CATEGORIA PRINCIPAL
                'categoria': categoria_principal,
                
                # B√°sico
                'title': self._safe_str(lot.get('lot_name') or lot.get('name')),
                'description': self._safe_str(lot.get('lot_description') or lot.get('description')),
                'image_url': self._parse_image(lot.get('lot_pictures') or lot.get('image_url')),
                'url': f"{self.base_url}/lote/{lot.get('id')}" if lot.get('id') else None,
                
                # Leil√£o
                'auction_date': self._parse_datetime(lot.get('lot_auction_date_init')),
                'auction_end_date': self._parse_datetime(lot.get('lot_auction_date_end')),
                'auction_type': self._safe_str(lot.get('auction_type') or lot.get('lot_auction_type')),
                'auctioneer': 'Sodr√© Santoro',
                
                # Valores
                'current_bid': self._parse_numeric(lot.get('lot_current_value')),
                'minimum_bid': self._parse_numeric(lot.get('lot_minimum_bid')),
                'estimated_value': self._parse_numeric(lot.get('lot_estimated_value')),
                'initial_value': self._parse_numeric(lot.get('lot_initial_value')),
                
                # Status
                'status': self._safe_str(lot.get('lot_status') or lot.get('status')),
                'is_active': lot.get('is_active', True),
                
                # Localiza√ß√£o
                'city': self._safe_str(lot.get('lot_city') or lot.get('city')),
                'state': self._safe_str(lot.get('lot_state') or lot.get('state')),
                
                # Ve√≠culos
                'vehicle_brand': self._safe_str(lot.get('lot_brand')),
                'vehicle_model': self._safe_str(lot.get('lot_model')),
                'vehicle_year': self._parse_int(lot.get('lot_year')),
                'vehicle_color': self._safe_str(lot.get('lot_color')),
                'vehicle_km': self._parse_int(lot.get('lot_km')),
                'vehicle_plate': self._safe_str(lot.get('lot_plate')),
                'vehicle_fuel': self._safe_str(lot.get('lot_fuel')),
                'lot_optionals': self._parse_optionals(lot.get('lot_optionals')),
                
                # Judicial
                'lot_number': self._safe_str(lot.get('lot_number')),
                'lot_judicial_process': self._safe_str(lot.get('lot_judicial_process')),
                'lot_judicial_vara': self._safe_str(lot.get('lot_judicial_vara')),
                'lot_judicial_district': self._safe_str(lot.get('lot_judicial_district')),
                'lot_judicial_judge': self._safe_str(lot.get('lot_judicial_judge')),
                'tj_praca_value': self._parse_numeric(lot.get('tj_praca_value')),
                'tj_praca_discount': self._parse_numeric(lot.get('tj_praca_discount')),
                
                # Im√≥veis - endere√ßo
                'lot_neighborhood': self._safe_str(lot.get('lot_neighborhood')),
                'lot_street': self._safe_str(lot.get('lot_street')),
                
                # Im√≥veis - caracter√≠sticas
                'lot_dormitories': self._parse_int(lot.get('lot_dormitories')),
                'lot_useful_area': self._parse_numeric(lot.get('lot_useful_area')),
                'lot_total_area': self._parse_numeric(lot.get('lot_total_area')),
                'lot_suites': self._parse_int(lot.get('lot_suites')),
                
                # Materiais - SUBCATEGORIA ORIGINAL
                'lot_subcategory': subcategory,
                'lot_type_name': self._safe_str(lot.get('lot_type_name')),
                
                # Metadata
                'metadata': self._build_metadata(lot),
            }
            
            # Remove None values
            return {k: v for k, v in item.items() if v is not None}
        
        except Exception as e:
            if self.debug:
                print(f"  ‚ö†Ô∏è Erro ao normalizar lote {lot.get('id')}: {e}")
            return None
    
    def _build_metadata(self, lot: Dict) -> Dict:
        """Constr√≥i metadata com campos extras"""
        metadata = {}
        
        # Campos extras
        extra_fields = [
            'segment_base', 'search_terms',
        ]
        
        for field in extra_fields:
            val = lot.get(field)
            if val:
                metadata[field] = val
        
        return metadata if metadata else {}
    
    def _parse_optionals(self, value):
        """Parse lot_optionals para array"""
        if not value:
            return None
        if isinstance(value, list):
            return [str(opt) for opt in value if opt]
        if isinstance(value, str):
            return [value]
        return None
    
    def _parse_image(self, value):
        """Parse image_url ou lot_pictures"""
        if not value:
            return None
        if isinstance(value, str):
            return value
        if isinstance(value, list) and len(value) > 0:
            return value[0]
        return None
    
    def _safe_str(self, value) -> str:
        if value is None:
            return None
        try:
            result = str(value).strip()
            return result if result else None
        except:
            return None
    
    def _parse_datetime(self, value) -> str:
        if not value:
            return None
        try:
            if isinstance(value, str):
                value = value.replace('Z', '+00:00')
                if 'T' in value:
                    return value
                try:
                    dt = datetime.strptime(value, '%Y-%m-%d %H:%M:%S')
                    return dt.strftime('%Y-%m-%dT%H:%M:%S+00:00')
                except:
                    pass
        except:
            pass
        return None
    
    def _parse_numeric(self, value):
        if value is None:
            return None
        try:
            return float(value)
        except:
            return None
    
    def _parse_int(self, value):
        if value is None:
            return None
        try:
            return int(value)
        except:
            return None


async def main():
    print("\n" + "="*70)
    print("üöÄ SODR√â SANTORO - SCRAPER CATEGORIZADO")
    print("="*70)
    print(f"üìÖ In√≠cio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*70)
    
    start_time = time.time()
    supabase = None
    
    try:
        if SupabaseClient:
            print("\nüíì Iniciando sistema de heartbeat...")
            supabase = SupabaseClient(
                service_name='sodre_scraper',
                service_type='scraper'
            )
            
            if supabase.test():
                supabase.heartbeat_start(metadata={
                    'scraper': 'sodre',
                    'version': 'categorizada',
                })
        
        print("\nüî• FASE 1: COLETANDO DADOS")
        scraper = SodreScraperCategorizado(debug=False)
        items = await scraper.scrape()
        
        print(f"\n‚úÖ Total coletado: {len(items)} itens")
        print(f"üî• Itens com lances: {scraper.stats['with_bids']}")
        print(f"‚ö†Ô∏è  Erros: {scraper.stats['errors']}")
        
        if not items:
            print("‚ö†Ô∏è Nenhum item coletado")
            if supabase:
                supabase.heartbeat_finish(status='warning', final_stats={
                    'items_collected': 0,
                })
            return
        
        # Salva JSON
        output_dir = Path(__file__).parent / 'data' / 'normalized'
        output_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        json_file = output_dir / f'sodre_{timestamp}.json'
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(items, f, ensure_ascii=False, indent=2)
        print(f"üíæ JSON: {json_file}")
        
        # Insere no Supabase
        if supabase:
            print("\nüì§ FASE 2: INSERINDO NO SUPABASE")
            print(f"\n  üì§ sodre_items: {len(items)} itens")
            stats = supabase.upsert('sodre_items', items)
            
            print(f"    ‚úÖ Inseridos/Atualizados: {stats['inserted']}")
            if stats.get('duplicates_removed', 0) > 0:
                print(f"    üîÑ Duplicatas removidas: {stats['duplicates_removed']}")
            if stats['errors'] > 0:
                print(f"    ‚ö†Ô∏è Erros: {stats['errors']}")
            
            # ‚úÖ Usa heartbeat_success() para manter status='active' e event='completed'
            supabase.heartbeat_success(final_stats={
                'items_collected': len(items),
                'items_inserted': stats['inserted'],
                'items_with_bids': scraper.stats['with_bids'],
                'duplicates_removed': stats.get('duplicates_removed', 0),
            })
    
    except Exception as e:
        print(f"‚ö†Ô∏è Erro cr√≠tico: {e}")
        if supabase:
            supabase.heartbeat_error(str(e)[:500])
    
    finally:
        elapsed = time.time() - start_time
        minutes = int(elapsed // 60)
        seconds = int(elapsed % 60)
        
        print("\n" + "="*70)
        print("üìä ESTAT√çSTICAS FINAIS")
        print("="*70)
        print(f"üü£ Sodr√© Santoro:")
        print(f"  ‚Ä¢ Total coletado: {scraper.stats['total_scraped']}")
        print(f"  ‚Ä¢ Com lances: {scraper.stats['with_bids']}")
        print(f"  ‚Ä¢ Erros: {scraper.stats['errors']}")
        print(f"\n‚è±Ô∏è Dura√ß√£o: {minutes}min {seconds}s")
        print(f"‚úÖ Conclu√≠do: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    asyncio.run(main())